{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ── 1. 메타 데이터 파싱 ──\n",
    "# meta_Movies_and_TV.json 파일에서 각 줄마다 파이썬 딕셔너리 형태로 저장된 데이터를 읽어, \n",
    "# asin(상품ID)와 영화 제목(title)을 매핑하는 딕셔너리를 생성합니다.\n",
    "meta_file_path = r\"C:\\Users\\user\\OneDrive\\문서\\과제\\2025-1\\캡스톤 디자인\\meta_Movies_and_TV.json\"\n",
    "\n",
    "asin_to_title = {}\n",
    "\n",
    "with open(meta_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            # 각 줄을 안전하게 파싱합니다.\n",
    "            data = ast.literal_eval(line)\n",
    "            asin = data.get('asin')\n",
    "            title = data.get('title')\n",
    "            if asin:\n",
    "                asin_to_title[asin] = title\n",
    "        except Exception as e:\n",
    "            print(f\"메타 데이터 파싱 오류 발생: {e}\")\n",
    "\n",
    "print(f\"총 {len(asin_to_title)}개의 메타 데이터를 파싱했습니다.\")\n",
    "\n",
    "# ── 2. CSV 파일(Chunk) 처리 ──\n",
    "# 각 파일은 예시로 movies_chunk_0.csv, movies_chunk_1.csv 등으로 저장되어 있다고 가정합니다.\n",
    "csv_folder = r\"C:\\Users\\user\\OneDrive\\문서\\과제\\2025-1\\캡스톤 디자인\\movies_chunk\"\n",
    "file_pattern = os.path.join(csv_folder, \"movies_chunk_*.csv\")\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"처리할 CSV 파일이 없습니다.\")\n",
    "else:\n",
    "    print(\"처리할 CSV 파일 목록:\")\n",
    "    for file in csv_files:\n",
    "        print(\"  \", file)\n",
    "\n",
    "# 각 CSV 파일을 순회하면서 처리합니다.\n",
    "for file_path in csv_files:\n",
    "    print(f\"\\n파일 처리 중: {file_path}\")\n",
    "    try:\n",
    "        # 1) CSV 파일 읽기\n",
    "        chunk_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 2) 'product/productId' 컬럼을 기준으로 영화 제목 추가\n",
    "        #    meta 데이터의 asin과 매칭하여 새로운 'movie_title' 컬럼에 저장합니다.\n",
    "        chunk_df['movie_title'] = chunk_df['product/productId'].map(asin_to_title)\n",
    "        \n",
    "        # 3) 결과를 새로운 CSV 파일로 저장 (파일명에 _with_title 추가)\n",
    "        output_path = file_path.replace(\".csv\", \"_with_title.csv\")\n",
    "        chunk_df.to_csv(output_path, index=False)\n",
    "        print(f\"저장 완료: {output_path}\")\n",
    "        \n",
    "        # 메모리 관리를 위해 DataFrame 삭제 (필요 시)\n",
    "        del chunk_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{file_path} 처리 중 오류 발생: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
